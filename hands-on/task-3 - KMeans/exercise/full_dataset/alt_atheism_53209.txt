Distribution: world
Message-ID: <1qlci4$bqp@fido.asd.sgi.com>
References: <1q0fngINNahu@gap.caltech.edu> <1q28ok$dt7@fido.asd.sgi.com> <1q56olINN8g9@gap.caltech.edu> <1q5gnr$s0g@fido.asd.sgi.com> <1q8m6kINNj4i@gap.caltech.edu> <1qcqfv$r05@fido.asd.sgi.com> <1ql7utINN5sg@gap.caltech.edu>
NNTP-Posting-Host: solntze.wpd.sgi.com

In article <1ql7utINN5sg@gap.caltech.edu>, keith@cco.caltech.edu (Keith Allan Schneider) writes:
|> livesey@solntze.wpd.sgi.com (Jon Livesey) writes:
|> 
|> >I want to know how this omniscient being is going to perform
|> >the feat of "definitely" terming actions right or wrong.
|> 
|> If you were omniscient, you'd know who exactly did what, and with what
|> purpose in mind.  Then, with a particular goal in mind, you sould be
|> able to methodically judge whether or not this action was in accordance
|> with the general goal.

But now you are contradicting yourself in a pretty massive way,
and I don't think you've even noticed.

In another part of this thread, you've been telling us that the
"goal" of a natural morality is what animals do to survive.

But suppose that your omniscient being told you that the long
term survival of humanity requires us to exterminate some 
other species, either terrestrial or alien.

Does that make it moral to do so?

jon. 
